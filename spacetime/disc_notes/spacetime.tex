\documentclass[a4paper,10pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb,amsfonts,stmaryrd}
\usepackage{soul}
\usepackage{array}
\usepackage{empheq}
\usepackage{xfrac}
\usepackage{minibox}
\usepackage{enumitem}
	\setlist{nosep} % or \setlist{noitemsep} to leave space around whole list
\usepackage{color}
\usepackage{blkarray}
\setcounter{MaxMatrixCols}{20}


\newcommand{\tcr}{\textcolor{blue}}
\newcommand{\tcb}{\textcolor{blue}}
\newcommand{\todo}[1]{\textcolor{red}{[TODO\@: #1]}}



\begin{document}
\allowdisplaybreaks


% ------------------------------------------------------------------------------------------------------- %
% ------------------------------------------------------------------------------------------------------- %
% ------------------------------------------------------------------------------------------------------- %
\section{Space-time discretizations}\label{sec:disc}

Consider a linear PDE of the form 
\begin{align*}
u_t + \mathcal{L}(u,\mathbf{x}) = g(\mathbf{x},t).
\end{align*}
We discretize $\mathcal{L}$ in space and, denoting $\mathbf{u}(t)$ the discrete solution in space at time $t$
and $\mathbf{g}(t)$ the corresponding right-hand side, we arrive at the system of ODEs 
%
\begin{align}\label{eq:ode}
\mathbf{u}_t + \mathcal{L}(t)\mathbf{u} = \mathbf{g}(t).
\end{align}
%
Note, in finite element discretizations, there will also be a mass matrix term:
%
\begin{align*}
M\mathbf{u}_t + \mathcal{L}(t)\mathbf{u} = \mathbf{g}(t).
\end{align*}
%
To consider Runge-Kutta schemes in space-time, let us express this as
%
\begin{align}\label{eq:odeM}
\mathbf{u}_t= -M^{-1}\mathcal{L}(t)\mathbf{u} + M^{-1}\mathbf{g}(t).
\end{align}
%

% ------------------------------------------------------------------------------------------------------- %
% ------------------------------------------------------------------------------------------------------- %
\subsection{One-stage}

Consider a one-stage DIRK Runge-Kutta schemes. Applied to \eqref{eq:odeM}, this takes the form
%
\begin{align*}
\mathbf{u}_{n+1} & = \mathbf{u}_{n} + \delta tb_1\mathbf{k}_1 , \\
\mathbf{k}_1 & = -M^{-1}\mathcal{L}(t_n+c_1\delta t)\left[ \mathbf{u}_n + \delta t a_{11}\mathbf{k}_1\right] + M^{-1}\mathbf{g}(t_n+c_1\delta t).
\end{align*}
%
Rearranging yields an implicit equation for $\mathbf{k}_1$,
%
\begin{align*}
(M + \delta t a_{11}\mathcal{L}(t_n+c_1\delta t))\mathbf{k}_1 & = -\mathcal{L}(t_n+c_1\delta t) \mathbf{u}_n + \mathbf{g}(t_n+c_1\delta t).
\end{align*}
%
The integration from time step $t_n$ to $t_{n+1}$ can be written as a block matrix equation in the form
%
\begin{align*}
\begin{bmatrix} I & \mathbf{0} \\ \mathcal{L}(t_n+c_1\delta t) & (M +\delta t a_{11}\mathcal{L}(t_n+c_1\delta t)) & \\ -I & -\delta tb_1I & I \end{bmatrix}
	\begin{bmatrix} \mathbf{u}_n \\ \mathbf{k}_1 \\ \mathbf{u}_{n+1} \end{bmatrix} = 
	\begin{bmatrix} \mathbf{0} \\ \mathbf{g}(t_n+c_1\delta t) \\ \mathbf{0} \end{bmatrix}.
\end{align*}
%
Considering a full time integration corresponds to a block lower triangular system, with overlapping $3\times 3$ blocks
of this form. For ease of notation, assume in this context that $\mathcal{L}$ is evaluated at time $t_n+c_1\delta t$ unless otherwise
noted. In this case, we can simplify the system by eliminating the row corresponding to $\mathbf{k}_1$ without causing additional
difficulties (with respect to implementation or solving). This is equivalent to solving for $\mathbf{u}_{n+1}$ in terms of
$\mathbf{u}_n$,
%
\begin{align*}
\mathbf{u}_{n+1} & = \mathbf{u}_{n} + \delta tb_1(M + \delta t a_{11}\mathcal{L})^{-1}\left[ -\mathcal{L}\mathbf{u}_n + \mathbf{g}(t_n+c_1\delta t) \right], \\
(\tfrac{1}{\delta t} M + a_{11}\mathcal{L})\mathbf{u}_{n+1} & = (\tfrac{1}{\delta t} M + a_{11}\mathcal{L})\mathbf{u}_n - b_1\mathcal{L} + b_1\mathbf{g}(t_n+c_1\delta t)
\end{align*}
%
and the reduced $2\times 2$ system then looks like
%
\begin{align*}
\begin{bmatrix} \frac{1}{\delta t} M + a_{11}\mathcal{L}(t_{n-1}+c_1\delta t) & \mathbf{0} \\ -(\frac{1}{\delta t} M + (a_{11}-b_1)\mathcal{L}) &
	 \frac{1}{\delta t} M + a_{11}\mathcal{L} \end{bmatrix}
	\begin{bmatrix} \mathbf{u}_n \\ \mathbf{u}_{n+1} \end{bmatrix} = 
	\begin{bmatrix} b_1 \mathbf{g}(t_{n-1}+c_1\delta t) \\ b_1 \mathbf{g}(t_{n}+c_1\delta t) \end{bmatrix}.
\end{align*}
%
There are three examples of one-stage methods, forward Euler, backward Euler, and the implicit midpoint. 
Plugging in values of $a_{11}, b_1, c_1$ for each of these schemes yields, respectively,
%
\begin{align*}
\begin{bmatrix} \frac{1}{\delta t}M & \mathbf{0} \\ -(\frac{1}{\delta t}M - \mathcal{L}_n) & \frac{1}{\delta t}M \end{bmatrix}
	\begin{bmatrix} \mathbf{u}_n \\ \mathbf{u}_{n+1} \end{bmatrix} & = 
	\begin{bmatrix} \mathbf{g}(t_{n-1}) \\ \mathbf{g}(t_{n}) \end{bmatrix}, \\
\begin{bmatrix} \frac{1}{\delta t}M -\mathcal{L}_n & \mathbf{0} \\ -\frac{1}{\delta t}M & \frac{1}{\delta t}M - \mathcal{L}_{n+1} \end{bmatrix}
	\begin{bmatrix} \mathbf{u}_n \\ \mathbf{u}_{n+1} \end{bmatrix} & = 
	\begin{bmatrix} \mathbf{g}(t_{n}) \\ \mathbf{g}(t_{n+1}) \end{bmatrix}, \\
\begin{bmatrix} \frac{1}{\delta t}M - \frac{1}{2}\mathcal{L}_{n-\frac{1}{2}} & \mathbf{0} \\ -(\frac{1}{\delta t}M - \frac{1}{2}\mathcal{L}_{n+\frac{1}{2}}) & \frac{1}{\delta t}M - \frac{1}{2}\mathcal{L}_{n+\frac{1}{2}} \end{bmatrix}
	\begin{bmatrix} \mathbf{u}_n \\ \mathbf{u}_{n+1} \end{bmatrix}  & = 
	\begin{bmatrix} \mathbf{g}(t_{n-\frac{1}{2}}) \\ \mathbf{g}(t_{n+\frac{1}{2}}) \end{bmatrix},
\end{align*}
%
where, for example, $\mathcal{L}_{n+1/2}$ corresponds to $\mathcal{L}(t_n + \delta t/2)$.

% ------------------------------------------------------------------------------------------------------- %
% ------------------------------------------------------------------------------------------------------- %
\subsection{Two-stage}

Now consider a two-stage DIRK Runge-Kutta method. Following similar steps as above to derive implicit
formulae for $\mathbf{k}_1$ and $\mathbf{k}_2$ yields
%
\begin{align*}
\tfrac{1}{\delta t}\mathbf{u}_{n+1} & = \tfrac{1}{\delta t}\mathbf{u}_{n} + b_1\mathbf{k}_1 + b_2\mathbf{k}_2 , \\
(M + \delta t a_{11}\mathcal{L}(t_n+c_1\delta t))\mathbf{k}_1 & = -\mathcal{L}(t_n+c_1\delta t) \mathbf{u}_n + \mathbf{g}(t_n+c_1\delta t), \\
(M + \delta t a_{22}\mathcal{L}(t_n+c_2\delta t))\mathbf{k}_2 & = -\mathcal{L}(t_n+c_2\delta t) \mathbf{u}_n -
	a_{21}\delta t\mathcal{L}(t_n+c_2\delta t) \mathbf{k}_1 + \mathbf{g}(t_n+c_2\delta t). 
\end{align*}
%
Proceeding similar to before, we now eliminate $k_2$ from the set of equations,
%
\begin{align*}
(\tfrac{1}{\delta t}M + a_{22}\mathcal{L}(t_n+c_2\delta t))\mathbf{u}_{n+1} & =
	(\tfrac{1}{\delta t}M + a_{22}\mathcal{L}(t_n+c_2\delta t))\mathbf{u}_{n} + b_1(M + \delta t a_{22}\mathcal{L}(t_n+c_2\delta t))\mathbf{k}_{1}
	\\ & \hspace{8ex}- b_2\mathcal{L}(t_n+c_2\delta t) \mathbf{u}_n - b_2a_{21}\delta t\mathcal{L}(t_n+c_2\delta t) \mathbf{k}_1 + b_2\mathbf{g}(t_n+c_2\delta t) \\
& = \left(\tfrac{1}{\delta t}M - (b_{2} - a_{22}) \mathcal{L}(t_n+c_2\delta t)\right)\mathbf{u}_{n} + ...
	 \\ & \hspace{8ex} \left(b_1M  - \delta t(b_2 a_{21} - b_1a_{22}) \mathcal{L}(t_n+c_2\delta t)\right) \mathbf{k}_1 + b_2\mathbf{g}(t_n+c_2\delta t).
\end{align*}
%
This yields a $3\times 3$ set of equations, where, in each row of the equation, $\mathcal{L}$ is evaluated at the same time
as $g(t)$ on the right-hand side of that row,
%
\begin{align*}
\begin{bmatrix} \tfrac{1}{\delta t}M + a_{22}\mathcal{L} & \mathbf{0}  & \mathbf{0}  \\
	\mathcal{L} & M + \delta ta_{11}\mathcal{L} & \mathbf{0} \\
	-\left(\tfrac{1}{\delta t}M - (b_2 - a_{22}) \mathcal{L}\right) & -\left(b_1M  - \delta t(b_2 a_{21} - b_1a_{22}) \mathcal{L}\right) &
	\tfrac{1}{\delta t}M + a_{22}\mathcal{L} \end{bmatrix}
	\begin{bmatrix} \mathbf{u}_n \\ \mathbf{k}_1 \\ \mathbf{u}_{n+1} \end{bmatrix} = 
	\begin{bmatrix} b_2\mathbf{g}(t_{n-1}+c_2\delta t) \\ \mathbf{g}(t_{n}+c_1\delta t) \\ b_2\mathbf{g}(t_{n}+c_2\delta t) \end{bmatrix}.
\end{align*}
%

Plugging in values from the Butcher tableaux, Heun's 2nd-order explicit method (i.e., explicit trapezoid) is given by 
%
% b = [1/2,1/2], c = [0,1], A = [0, 0; 1, 0]
\begin{align*}
\begin{bmatrix} \tfrac{1}{\delta t}M & \mathbf{0}  & \mathbf{0}  \\
	\mathcal{L} & M & \mathbf{0} \\
	-\left(\tfrac{1}{\delta t}M - \frac{1}{2}\mathcal{L}\right) & -\left(\frac{1}{2}M - \frac{1}{2}\delta t\mathcal{L}\right) & \tfrac{1}{\delta t}M \end{bmatrix}
	\begin{bmatrix} \mathbf{u}_n \\ \mathbf{k}_1 \\ \mathbf{u}_{n+1} \end{bmatrix} = 
	\begin{bmatrix} \frac{1}{2}\mathbf{g}(t_{n}) \\ \mathbf{g}(t_{n}) \\ \frac{1}{2}\mathbf{g}(t_{n+1}) \end{bmatrix}.
\end{align*}
%
Crank-Nicolson, also known as implicit trapezoid, takes the form
%
% b = [1/2,1/2], c = [0,1], A = [0, 0; 1/2, 1/2]
\begin{align*}
\begin{bmatrix} \tfrac{1}{\delta t}M + \frac{1}{2}\mathcal{L} & \mathbf{0}  & \mathbf{0}  \\
	\mathcal{L} & ~~M  & \mathbf{0} \\
	-\tfrac{1}{\delta t}M& -\frac{1}{2}M & \tfrac{1}{\delta t}M + \frac{1}{2}\mathcal{L} \end{bmatrix}
	\begin{bmatrix} \mathbf{u}_n \\ \mathbf{k}_1 \\ \mathbf{u}_{n+1} \end{bmatrix} = 
	\begin{bmatrix} b_2\mathbf{g}(t_{n}) \\ \mathbf{g}(t_{n}) \\ b_2\mathbf{g}(t_{n+1}) \end{bmatrix}.
\end{align*}
%
There are a number of two-stage implicit methods. One example is the 2nd-order L-stable SDIRK method, 
%
\begin{align*}
\begin{bmatrix} \tfrac{1}{\delta t}M + \gamma\mathcal{L} & \mathbf{0}  & \mathbf{0}  \\
	\mathcal{L} & M + \delta t\gamma\mathcal{L} & \mathbf{0} \\
	-\tfrac{1}{\delta t}M & -(1-\gamma)M & \tfrac{1}{\delta t}M + \gamma\mathcal{L} \end{bmatrix}
	\begin{bmatrix} \mathbf{u}_n \\ \mathbf{k}_1 \\ \mathbf{u}_{n+1} \end{bmatrix} = 
	\begin{bmatrix} \gamma\mathbf{g}(t_{n}) \\ \mathbf{g}(t_{n}+\gamma\delta t) \\ \gamma\mathbf{g}(t_{n+1}) \end{bmatrix},
\end{align*}
%
for $\gamma = 1 + \frac{\sqrt{2}}{2}$.

% ------------------------------------------------------------------------------------------------------- %
% ------------------------------------------------------------------------------------------------------- %
\subsection{Three-stage}

Repeating the process for three stages, a DIRK scheme takes the form
%
\begin{align*}
\tfrac{1}{\delta t}\mathbf{u}_{n+1} & = \tfrac{1}{\delta t}\mathbf{u}_{n} + b_1\mathbf{k}_1 + b_2\mathbf{k}_2 + b_3\mathbf{k}_3, \\
(M + \delta t a_{11}\mathcal{L}(t_n+c_1\delta t))\mathbf{k}_1 & = -\mathcal{L}(t_n+c_1\delta t) \mathbf{u}_n + \mathbf{g}(t_n+c_1\delta t), \\
(M + \delta t a_{22}\mathcal{L}(t_n+c_2\delta t))\mathbf{k}_2 & = -\mathcal{L}(t_n+c_2\delta t) \mathbf{u}_n -
	a_{21}\delta t\mathcal{L}(t_n+c_2\delta t) \mathbf{k}_1 + \mathbf{g}(t_n+c_2\delta t), \\
(M + \delta t a_{33}\mathcal{L}(t_n+c_3\delta t))\mathbf{k}_3 & = -\mathcal{L}(t_n+c_3\delta t) \mathbf{u}_n -
	a_{31}\delta t\mathcal{L}(t_n+c_3\delta t) \mathbf{k}_1 - \\&\hspace{10ex}a_{32}\delta t\mathcal{L}(t_n+c_3\delta t) \mathbf{k}_2 + \mathbf{g}(t_n+c_3\delta t). 
\end{align*}
%
Eliminating $\mathbf{k}_3$ yields
%
\begin{align*}
(\tfrac{1}{\delta t}M + a_{33}\mathcal{L}(t_n+c_3\delta t))\mathbf{u}_{n+1} & =
	\left(\tfrac{1}{\delta t}M + a_{33}\mathcal{L}(t_n+c_3\delta t)\right)\mathbf{u}_{n} + 
	b_1\left(M + \delta t a_{33}\mathcal{L}(t_n+c_3\delta t)\right)\mathbf{k}_{1}
	\\ & \hspace{8ex} + b_2\left(M + \delta t a_{33}\mathcal{L}(t_n+c_3\delta t)\right)\mathbf{k}_{2} - b_3\mathcal{L}(t_n+c_3\delta t) \mathbf{u}_n -
	\\ & \hspace{8ex} b_3a_{31}\delta t\mathcal{L}(t_n+c_3\delta t) \mathbf{k}_1 - 
	b_3a_{32}\delta t\mathcal{L}(t_n+c_3\delta t) \mathbf{k}_2 + b_3\mathbf{g}(t_n+c_3\delta t) \\
& = \left(\tfrac{1}{\delta t}M - (b_3-a_{33})\mathcal{L}(t_n+c_3\delta t)\right)\mathbf{u}_{n} + 
	\\ & \hspace{8ex}\left(b_1M - \delta t( b_3a_{31}- b_1a_{33})\mathcal{L}(t_n+c_3\delta t)\right)\mathbf{k}_{1} +
	\\ & \hspace{8ex}\left(b_2M - \delta t (b_3a_{32} - b_2a_{33})\mathcal{L}(t_n+c_3\delta t)\right)\mathbf{k}_{2} + b_3\mathbf{g}(t_n+c_3\delta t).
\end{align*}
%
In matrix form, we have
%
{\small
\begin{align*}
\begin{bmatrix} \tfrac{1}{\delta t}M + a_{33}\mathcal{L} & \mathbf{0}  & \mathbf{0} & \mathbf{0}  \\
	\mathcal{L} & M + \delta ta_{11}\mathcal{L} & \mathbf{0} & \mathbf{0} \\
	\mathcal{L} & \delta t a_{21}\mathcal{L} & M + \delta ta_{22}\mathcal{L} & \mathbf{0} \\
	-\left(\tfrac{1}{\delta t}M - (b_3-a_{33})\mathcal{L}\right) & -\left(b_1M  - \delta t(b_3 a_{31} - b_1a_{33}) \mathcal{L}\right) &
	-\left(b_2M  - \delta t(b_3 a_{32} - b_2a_{33}) \mathcal{L}\right) & \tfrac{1}{\delta t}M + a_{33}\mathcal{L}  \end{bmatrix}
	\\
	\begin{bmatrix} \mathbf{u}_n \\ \mathbf{k}_1 \\ \mathbf{k}_2 \\ \mathbf{u}_{n+1} \end{bmatrix} =
	\begin{bmatrix} b_3\mathbf{g}(t_{n-1}+c_3\delta t) \\ \mathbf{g}(t_{n}+c_1\delta t) \\ \mathbf{g}(t_{n}+c_2\delta t) \\ b_3\mathbf{g}(t_{n}+c_3\delta t) \end{bmatrix}.
\end{align*}}
%

For example, plugging in values for explicit 3rd-order SSP RK yields
%\begin{array}{c|ccc}
%0   & 0   & 0   & 0    \\
%1   & 1   & 0   & 0    \\
%1/2 & 1/4 & 1/4 & 0    \\
%\hline
%    & 1/6 & 1/6 & 2/3  \\
%\end{array}
\begin{align*}
\begin{bmatrix} \tfrac{1}{\delta t}M & \mathbf{0}  & \mathbf{0} & \mathbf{0}  \\
	\mathcal{L} & M & \mathbf{0} & \mathbf{0} \\
	\mathcal{L} & \delta t \mathcal{L} & M & \mathbf{0} \\
	-\left(\tfrac{1}{\delta t}M - \tfrac{2}{3}\mathcal{L}\right) & -\left(\tfrac{1}{6}M  - \tfrac{2}{3}\delta t\mathcal{L}\right) &
	-\left(\tfrac{1}{6}M  - \tfrac{1}{6}\delta t \mathcal{L}\right) & \tfrac{1}{\delta t}M \end{bmatrix}
	\begin{bmatrix} \mathbf{u}_n \\ \mathbf{k}_1 \\ \mathbf{k}_2 \\ \mathbf{u}_{n+1} \end{bmatrix} =
	\begin{bmatrix} \tfrac{2}{3}\mathbf{g}(t_{n-\frac{1}{2}}) \\ \mathbf{g}(t_{n}) \\ \mathbf{g}(t_{n+1}) \\ \tfrac{2}{3}\mathbf{g}(t_{n+\frac{1}{2}}) \end{bmatrix}.
\end{align*}
%
Constants in ESDIRK and SDIRK schemes are more complicated, so explicit operators are not expressed here.
However, the structure remains the same, where all entries take the form of $C_1M + C_2\mathcal{L}$, for
some constants $C_1$ and $C_2$. Furthermore, from the general form of three-stage DIRK methods
expressed above, it is easy to extrapolate the structure to an arbitrary number of stages.


% ------------------------------------------------------------------------------------------------------- %
% ------------------------------------------------------------------------------------------------------- %
\subsection{$s$-stages}
The RK update for a general $s \geq 1$-stage RK scheme is
\begin{align*}
\mathbf{u}_{n+1} = \mathbf{u}_{n} + \delta t \sum \limits_{i = 1}^s b_i \mathbf{k}_i.
\end{align*}
The stage vectors of an RK scheme with lower-triangular Butcher tableaux $(a_{ij} = 0, \, j > i)$ applied to ODEs \eqref{eq:odeM} satisfy
\begin{align*}
\mathbf{k}_i 
&= 
- M^{-1} {\cal L}(t_n + c_i \delta t) \mathbf{u}_{n} 
- \delta t \sum \limits_{j = 1}^{i} a_{ij} M^{-1} {\cal L}(t_n + c_i \delta t) \mathbf{k}_{n} 
+ M^{-1} \mathbf{g}(t_n + c_i \delta t),
\quad
i = 1,\ldots,s,
\end{align*}
or, rearranging,
\begin{align*}
\big[ M + \delta t a_{ii} {\cal L}(t_n + c_i \delta t) \big] \mathbf{k}_i 
&= 
- {\cal L}(t_n + c_i \delta t) \mathbf{u}_{n} 
- \delta t \sum \limits_{j = 1}^{i-1} a_{ij} {\cal L}(t_n + c_i \delta t) \mathbf{k}_{j} 
+ \mathbf{g}(t_n + c_i \delta t),
\quad
i = 1,\ldots,s.
\end{align*}
Thus, eliminating $\mathbf{k}_s$ from the RK update yields
\begin{align*}
\mathbf{u}_{n+1} 
= 
\mathbf{u}_{n} + \delta t \sum \limits_{i = 1}^{s-1} b_i \mathbf{k}_i
+ \delta t b_s 
\big[ 
M + \delta t a_{ss} {\cal L}(t_n + c_s \delta t) 
\big]^{-1}
\big[
- {\cal L}(t_n + c_s \delta t) \mathbf{u}_{n} 
- \delta t \sum \limits_{i = 1}^{s-1} a_{si} {\cal L}(t_n + c_s \delta t) \mathbf{k}_{i} 
+ \mathbf{g}(t_n + c_s \delta t)
\big],
\end{align*}
or, rearranging,
\begin{align*}
\big[ 
\tfrac{1}{\delta t} M + a_{ss} {\cal L}(t_n + c_s \delta t) 
\big] 
\mathbf{u}_{n+1} 
&= 
\big[ 
\tfrac{1}{\delta t} M + ( a_{ss} - b_s) {\cal L}(t_n + c_s \delta t) 
\big] 
\mathbf{u}_{n} \\
&\quad
+ \sum \limits_{i = 1}^{s-1} 
\big[
b_i M + \delta t  (b_i a_{ss} - b_s a_{si}) {\cal L}(t_n + c_s \delta t)
\big] \mathbf{k}_i
+
b_s \mathbf{g}(t_n + c_s \delta t).
\end{align*}
Note that the elimination of $\mathbf{k}_s$ from the system only changes the equation for $\mathbf{u}_{n+1}$ as stages $\mathbf{k}_i, \, i < s,$ do not depend on $\mathbf{k}_s$, i.e., the system of equations is lower triangular.

So, in all of their glory, the (block) lower triangular system of equations marching the solution from $t_n$ to $t_{n+1}$ is
\begin{align} \label{eq:time_step_w_stages}
\begin{split}
\big[ M + \delta t a_{ii} {\cal L}(t_n + c_i \delta t) \big] \mathbf{k}_i 
&= 
- {\cal L}(t_n + c_i \delta t) \mathbf{u}_{n} 
- \delta t \sum \limits_{j = 1}^{i-1} a_{ij} {\cal L}(t_n + c_i \delta t) \mathbf{k}_{j} 
+ \mathbf{g}(t_n + c_i \delta t),
\quad
i = 1,\ldots,s-1, \\
\big[ 
\tfrac{1}{\delta t} M + a_{ss} {\cal L}(t_n + c_s \delta t) 
\big] 
\mathbf{u}_{n+1} 
&= 
\big[ 
\tfrac{1}{\delta t} M + ( a_{ss} - b_s) {\cal L}(t_n + c_s \delta t) 
\big] 
\mathbf{u}_{n} \\
&\quad
+ \sum \limits_{i = 1}^{s-1} 
\big[
b_i M + \delta t  (b_i a_{ss} - b_s a_{si}) {\cal L}(t_n + c_s \delta t)
\big] \mathbf{k}_i
+
b_s \mathbf{g}(t_n + c_s \delta t).
\end{split}
\end{align}
Note that at $t = 0$, these equations are supplemented with an initial condition $\mathbf{u}_0 = u(\mathbf{x},0)$.

\textcolor{red}{\textbf{Ben}: do you think it's a good idea to scale these stage equations by $1/\delta t$ such that the block diagonal has the same scaling for the stages and the solution? But I guess at the moment the columns have the same scaling (which we destroy if we rescale rows)}
\tcb{I wondered about this too.. AIR is in theory invariant to row scaling of the matrix, which is a nice property. I
had decided no initially just so we didn't have to scale the right-hand side, but it may be good to keep the scaling
a bit more balanced. 
In looking at that, I found the off-diagonal blocks for $\mathbf{k}$ puzzling. $M$ should scale like $h^2$ and 
$\mathcal{L}$ should scale like $h$ for advection and $h^2$ for diffusion. Also, $\mathcal{L}$ should be in some
sense a positive operator. So for explicit schemes, $\mathcal{L}$ seems like a large, positive off-diagonal (block), which is
probably larger than the diagonal block (entry-wise anyways). Usually this is not what you get with FD-type
discretizations}





% ------------------------------------------------------------------------------------------------------- %
% ------------------------------------------------------------------------------------------------------- %
\subsection{Code structure}

The code should be general enough that it can do spatial and temporal parallelism, but we don't have to go crazy with
arbitrary numbers of processors. Let $P$ denote the number of processors, $s$ the number of stages, and 
$N_t$ the number of time steps. We have two cases:
%
\begin{itemize}
\item $P > N_ts$: Here, we have more processors than all time steps and RK stages. In this case, we must introduce
spatial parallelism as well. The simplest solution is to require that $N_ts$ divides $P$. Then, each stage will be split
across some number of processors in a logically sequential fashion. A more general option is to require that $N_t$
divides $P$. This would make it easier to support spatial parallelism without having to pick very specific numbers of
processors and time steps. However, it would also reorder the matrix in a somewhat strange way, where one processor
would own multiple stages of a subdomain of the problem (which would be ordered sequentially in the matrix). From a
meshing perspective, it is possible this is actually better, but it's a but more complicated.

\item $P \leq N_ts$: I think the best way to do this is to require that $P$ divides $N_ts$, and implement to support
an arbitrary number of stages per processor. The only difficult is that these stages may or may not correspond to
the same time step. However, the block systems are sufficiently structured that I don't think this will be a huge deal,
and it will make the code a good amount more flexible. 

\item \textcolor{red}{Re: space-time parallelism $(P > N_t s)$ vs temporal-only parallelism $(P \leq N_t s)$:} I'm not sure that what we have done above is the correct thing to do. It seems like the right thing to do in terms of how the problem is set up, but not with respect to the way we need to be thinking about parallel-in-time. 
\begin{enumerate}
\item \textit{Parallelism from the perspective of the block linear system.} This is where I think what we are doing make sense. The matrix is blocked by rows (each block corresponds to a solution or stage), so when we have less processors than block rows ($P \leq N_t s $) we introduce parallelism across blocks (at least one block DOF per processor, be it a solution or stage value). When we have more processors than block rows ($P > N_t s$), we add parallelism into blocks (a single block DOF is distributed over more than one processor).

Even though MGRIT solves the same block linear system (although the stage values would be excluded), it doesn't parallelize like this. It parallelizes first within blocks, and then temporal parallelism is introduced. One major difference here though is that $\Phi$ and intermediate solution values don't even need to be stored in memory, unlike in our approach. 
\item \textit{Parallelism from the parallel-in-time perspective.} This is where what we're doing seems funny. The way parallel-in-time is thought about is that you saturate first the spatial parallelism, then you can add remaining resources in time. Note: It makes sense to do it in this ordering since temporal parallelism is typically much less efficient than spatial parallelism. 

But, we're essentially doing the reverse of this: We add temporal parallelism, then given enough resources, we also add spatial parallelism, so I don't really understand how we'll ever be able to compete with sequential time stepping? The set up of the problem naturally means that we have to be fully parallelized in time before we can think about parallelizing in space.

Note: There is no difference between the two approaches if we have enough processors. However, we're easily going to run into a situation where that's not the case. E.g., if we take $10^5$ time steps (this is within reason), we're going to need $P > s 10^5$ processors before we can even introduce spatial parallelism. Thus, I think quite often we're going to find ourselves in a regime of using temporal-only parallelism and not space-time parallelism that's saturated in space, like we want to. 
\end{enumerate}
\end{itemize}
\noindent\textbf{Implementation:}
\begin{itemize}
\item Take in Butcher tableaux as arrays $A,b,c$. Use the equations derived here to map these to some 2d array
representation(s) with coefficients for $M$ and $\mathcal{L}$ in the $s \times s$ block equations corresponding to
a given time step.

\item Use processor id to determine which time step(s) and stages you are responsible for, and the time that each
stage is evaluated at.

\item Use the coefficients computed above to estimate nonzero allocation. Baseline should be nnz of $M$ plus
nnz of $\mathcal{L}$ for every lower triangular block (including both is important; they largely overlap, but the
seg faults we were getting were because there were certain spots that they didn't). Then, any coefficients that
are zero, remove (or don't add in the first place).

\item Construct operator very similarly to current FE/BE code, but here you loop over stages. For each stage, get
the operator $L$, right-hand side, and mass matrix, and use the coefficients to build the rows of the global space-time
matrix. If $\mathcal{L}$ is not time dependent, you should be able to compute it once and just update the right-hand
side.

\item \textcolor{red}{Question:} the 1st equation in the space-time system reads $I \mathbf{u}_0 = \mathbf{u}_0 \equiv {\rm initial\, condition}$. Do we want to scale this block row by something like 
\[
\tfrac{1}{\delta t} M + a_{ss} {\cal L}(t_0 + c_s \delta t) 
\]
so that the scaling of this row is consistent with the other equations? AIR might not like it if there are different scales going on here.
\tcb{As above, AIR is invariant to row scaling. Mostly I think we want to make the matrix entries $\mathcal{O}(1)$ where possible.}

\end{itemize}

\noindent\textbf{Other TODOs:}
\begin{itemize}
\item Construct functions that do sequential RK time stepping. There are obviously other codes that do
this, but I don't think it would be very much work, and it would be nice to be able to directly compare methods
for any DIRK scheme we want. I think we can add to the same class and use the RK tableaux we pass in. 
Just write a semi-general time-stepping function that uses the mass and spatial matrix to do the
explicit or implicit steps sequentially. For implicit, we will convert the spatial matrix to a parallel hypre
matrix and use hypre for the linear solves. 

\item Add timings for setup and solve phase. Add timing for AMG setup phase in sequential time stepping.
If is time dependent, have to rebuild every time which is expensive. Space-time only builds once. 

\end{itemize}





\subsection{Some further implementation details}
\textit{This section is helpful to look at when implementing the code/understanding it.} \\

\noindent A few remarks on the code structure/problem set up
\begin{itemize}
\item $N_t$ time points: $0 \equiv t_0 < t_1 < \ldots < t_{N_t-1} \equiv T$, where $t_n \coloneqq n \delta t$
\item Take $N_t-1$ time steps to get from $t_0$ to $t_{N_t-1}$
\item Mesh spacing $\Delta t = t_{n+1} - t_{n}$ is assumed constant $\forall n$
\item This formulation unfortunately ignores the solution at the final time, $\mathbf{u}_{N_t-1}$. Including $\mathbf{u}_{N_t-1}$ makes distributing processors very awkward since then there are $N_t s + 1$ DOFs. One possibility is to eliminate the initial condition, $\mathbf{u}_0$, from the system by adding it to the RHS. However, this leads to its own awkwardness because the stages defined over $t \in [t_0,t_1]$ require linear solves and matrix-vector products using the spatial discretization and $\mathbf{u}_0$, which is going to be a mess...
\end{itemize}

\noindent \underline{For $n = 0$:}
\begin{align}
\label{eq:implement_n0}
\begin{split}
I \mathbf{u}_n &= u(\mathbf{x},0) \\
\big[ M + \delta t a_{ii} {\cal L}(t_n + c_i \delta t) \big] \mathbf{k}_{n,i} 
&= 
- {\cal L}(t_n + c_i \delta t) \mathbf{u}_{n} 
- \delta t \sum \limits_{j = 1}^{i-1} a_{ij} {\cal L}(t_n + c_i \delta t) \mathbf{k}_{n,j} 
+ \mathbf{g}(t_n + c_i \delta t),
\quad
i = 1,\ldots,s-1.
\end{split}
\end{align}
\underline{And for $n \in \{1,2,\ldots,N_t-1\}$}\footnote{Note that $t_n \neq t_{n-1} + c_s \delta t $ for general RK schemes, which is why the equation for $\mathbf{u}_n$ references the previous time level, $t_{n-1}$. Recall that this time appears in this equation due to the elimination of the last stage, $\mathbf{k}_{n,s}$, which is defined at this time.}:
\begin{align} 
\label{eq:implement_ngeneral}
\begin{split}
\big[ 
\tfrac{1}{\delta t} M + a_{ss} {\cal L}(t_{n-1} + c_s \delta t) 
\big] 
\mathbf{u}_{n} 
&= 
\big[ 
\tfrac{1}{\delta t} M + ( a_{ss} - b_s) {\cal L}(t_{n-1} + c_s \delta t) 
\big] 
\mathbf{u}_{n-1} \\
&\quad
+ \sum \limits_{i = 1}^{s-1} 
\big[
b_i M + \delta t  (b_i a_{ss} - b_s a_{si}) {\cal L}(t_{n-1} + c_s \delta t)
\big] \mathbf{k}_{n-1,i}
+
b_s \mathbf{g}(t_{n-1} + c_s \delta t), \\
\big[ M + \delta t a_{ii} {\cal L}(t_n + c_i \delta t) \big] \mathbf{k}_{n,i} 
&= 
- {\cal L}(t_n + c_i \delta t) \mathbf{u}_{n} 
- \delta t \sum \limits_{j = 1}^{i-1} a_{ij} {\cal L}(t_n + c_i \delta t) \mathbf{k}_{n,j} 
+ \mathbf{g}(t_n + c_i \delta t),
\quad
i = 1,\ldots,s-1.
\end{split}
\end{align}
Notice that the structure of the equation for $\mathbf{u}_0$ in \eqref{eq:implement_n0} is different to that for $\mathbf{u}_n$, $n > 0$, in \eqref{eq:implement_ngeneral}, and, so a separate implementation is required. There is a total of $s N_t$ variables (ignoring the number of spatial DOFs).

The entire space-time system is naturally blocked into blocks of $s$ equations/unknowns. We can write these as the variables
\begin{align}
\mathbf{v}_n = (\mathbf{u}_n, \mathbf{k}_{n,1}, \ldots, \mathbf{k}_{n,s-1})^\top, \quad n \in \{0,\ldots,N_t-1\}.
\end{align}
The space-time linear system can be written in the form of a block lower triangular system for $\mathbf{v}$:
\begin{align}
\begin{bmatrix}
\Phi^{\rm I}_0 & \\
\Phi^{\rm E}_1 & \Phi^{\rm I}_1 &  \\
					& \ddots & \ddots \\
					& 				& \Phi^{\rm E}_{N_t-1} & \Phi^{\rm I}_{N_t-1} &  \\
\end{bmatrix}
\begin{bmatrix}
\mathbf{v}_{0} \\
\mathbf{v}_{1} \\ 
\vdots \\
\mathbf{v}_{N_t-1} \\
\end{bmatrix}
= \cdots
\end{align} \\

\noindent \textbf{Time-only parallelism:}  This happens when we have a number of processors $P \leq s N_t$. Each processor then owns $\frac{s N_t}{P} \in \mathbb{N}$ DOFs. Note that this doesn't have to be one, and it does not have to be $s$, i.e., the vector $\mathbf{v}_n$ can be split across multiple processors, or one processor can own many such variables. 

In the implementation, we need to be able to distinguish between the different types of variables in the vectors $\mathbf{v}_n$, and so it's convenient to index them as in Table \ref{tab:variable_inds}.
\begin{table}[h]
\caption{Indexing for variables in implementation. \label{tab:variable_inds}}
\centering
\begin{tabular}{c|c|c|c}
variable & global index & block index & local index \\ \hline 
$\mathbf{v}_n$ & -- & $n$ & --  \\
$\mathbf{u}_n$ & $ns$ & $n$ & $0$  \\
$\mathbf{k}_{n,i}$ & $ns+i$ & $n$ & $i$  \\ 
\end{tabular}
\end{table}


\noindent \textbf{Space-time parallelism:} This happens when we have a number of processors $P > s N_t$.

\noindent \textbf{\textcolor{red}{Questions:}}
\begin{enumerate}
\item Do we really need to explicitly check that mass matrix data and spatial discretization data is not zero/not smaller than 1e-16? It seems like it just creates unnecessary overhead? If the user explicitly passes zeros in with the mass matrix and spatial discretization then the implementation won't be as efficient as possible, but isn't that their fault for not properly sparsifying their operators?
\item One thing to be aware of is supplying boundary conditions for RK stages. Is there a natural way to do this for FEM methods? For FD/FV methods this is completely non-trivial unless using periodic boundaries. 
\end{enumerate}




\end{document}